{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \n",
    "Author: Vitaly Radchenko (@vradchenko), [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Sergey Volkov (@sevaspb). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Assignment #5. Fall 2018\n",
    "## <center> RandomForest and Logistic Regression in credit scoring and movie reviews classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Here we will develop and tune models for credit scoring and movies reviews sentiment prediction. Fill the code where needed (\"#Your code is here\") and answer the questions in the [web form](https://docs.google.com/forms/d/1MS3kW_bjZQAkwwlAjX9G8khj1owq1qc5NQtjzJUvKVo).\n",
    "\n",
    "For the warm-up, solve the first task.\n",
    "\n",
    "<font color = 'red'> **Task 1:** </font> There are 7 jurors in the courtroom. Each of them individually can correctly determine whether the defendant is guilty or not with 80% probability. How likely is the jury will make a correct verdict jointly if the decision is made by majority voting?\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a5_q1__*\n",
    "\n",
    "<font color = 'red'> **Answer options:** </font>\n",
    "- 20.97%\n",
    "- 80.00%\n",
    "- 83.70%\n",
    "- 96.66%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.66560000000001\n"
     ]
    }
   ],
   "source": [
    "# Your code is here\n",
    "import math\n",
    "\n",
    "p = 0.8\n",
    "N = 7\n",
    "u = 0.0\n",
    "for i in range(math.floor (N / 2) + 1, N + 1):\n",
    "    C = math.factorial (N) / (math.factorial (N - i) * math.factorial (i))\n",
    "    u = u + C * p ** i * (1 - p) ** (N - i)\n",
    "print(u * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move directly to machine learning.\n",
    "\n",
    "#### The data looks this way:\n",
    "\n",
    "##### Target variable\n",
    "* SeriousDlqin2yrs - the person had long delays in payments during 2 years; binary variable\n",
    "\n",
    "##### Features\n",
    "* age - Age of the loan borrower (number of full years); type - integer\n",
    "* NumberOfTime30-59DaysPastDueNotWorse - the number of times a person has had a delay in repaying other loans more than 30-59 days (but not more) during last two years; type - integer\n",
    "* DebtRatio - monthly payments (loans, alimony, etc.) divided by aggregate monthly income, percentage; float type\n",
    "* MonthlyIncome - monthly income in dollars; float type\n",
    "* NumberOfTimes90DaysLate - the number of times a person has had a delay in repaying other loans for more than 90 days; type - integer\n",
    "* NumberOfTime60-89DaysPastDueNotWorse - the number of times a person has had a delay in repaying other loans more than 60-89 days (but not more) in the last two years; type - integer\n",
    "* NumberOfDependents - number of people in the family of the borrower; type - integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us implement a function that will replace the NaN values by the median in each column of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_nan_with_median(table):\n",
    "    for col in table.columns:\n",
    "        table[col]= table[col].fillna(table[col].median())\n",
    "    return table   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8158.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3870.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6666.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  age  NumberOfTime30-59DaysPastDueNotWorse    DebtRatio  \\\n",
       "0                 0   64                                     0     0.249908   \n",
       "1                 0   58                                     0  3870.000000   \n",
       "2                 0   41                                     0     0.456127   \n",
       "3                 0   43                                     0     0.000190   \n",
       "4                 1   49                                     0     0.271820   \n",
       "\n",
       "   NumberOfTimes90DaysLate  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                        0                                     0   \n",
       "1                        0                                     0   \n",
       "2                        0                                     0   \n",
       "3                        0                                     0   \n",
       "4                        0                                     0   \n",
       "\n",
       "   MonthlyIncome  NumberOfDependents  \n",
       "0         8158.0                 0.0  \n",
       "1            NaN                 0.0  \n",
       "2         6666.0                 0.0  \n",
       "3        10500.0                 2.0  \n",
       "4          400.0                 0.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/credit_scoring_sample.csv', sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View data types of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriousDlqin2yrs                          int64\n",
       "age                                       int64\n",
       "NumberOfTime30-59DaysPastDueNotWorse      int64\n",
       "DebtRatio                               float64\n",
       "NumberOfTimes90DaysLate                   int64\n",
       "NumberOfTime60-89DaysPastDueNotWorse      int64\n",
       "MonthlyIncome                           float64\n",
       "NumberOfDependents                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the distribution of classes in target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.777511\n",
       "1    0.222489\n",
       "Name: SeriousDlqin2yrs, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = data['SeriousDlqin2yrs'].hist(orientation='horizontal', color='red')\n",
    "ax.set_xlabel(\"number_of_observations\")\n",
    "ax.set_ylabel(\"unique_value\")\n",
    "ax.set_title(\"Target distribution\")\n",
    "\n",
    "print('Distribution of target:')\n",
    "data['SeriousDlqin2yrs'].value_counts() / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all the features and drop the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'NumberOfTime30-59DaysPastDueNotWorse',\n",
       " 'DebtRatio',\n",
       " 'NumberOfTimes90DaysLate',\n",
       " 'NumberOfTime60-89DaysPastDueNotWorse',\n",
       " 'MonthlyIncome',\n",
       " 'NumberOfDependents']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_columns_names = data.columns.values\n",
    "independent_columns_names = [x for x in data if x != 'SeriousDlqin2yrs']\n",
    "independent_columns_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a function that replaces all values of NaN by the median value of the corresponding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = impute_nan_with_median(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the target and features - now we get a training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = table[independent_columns_names]\n",
    "y = table['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap\n",
    "\n",
    "**<font color = 'red'> Task 2. </font>** Make an interval estimate based on the bootstrap of the average income (MonthlyIncome)  of customers who had overdue loan payments, and of those who paid in time, make 90% confidence interval. Find the difference between the lower limit of the derived interval for those who paid in time and the upper limit for those who are overdue.\n",
    "So, you are asked to build 90% intervals for the income of \"good\" customers $ [good\\_income\\_lower, good\\_income\\_upper] $ and for \"bad\" - $ [bad\\_income\\_lower, bad\\_income\\_upper] $ and find the difference $ good\\_income\\_lower - bad\\_income\\_upper $.\n",
    "\n",
    "Use the example from the [article](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-5-ensembles-of-algorithms-and-random-forest-8e05246cbba7). Set `np.random.seed (17)`. Round the answer to the integer value.\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a5_q2__*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Answer options:</font>**\n",
    "- 344\n",
    "- 424\n",
    "- 584\n",
    "- 654"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly income of good customers: mean interval [6295.93237577 6505.35467934]\n",
      "Monthly income of bad customers: mean interval [5471.64826451 5643.93562737]\n",
      "Difference good_income_lowerâˆ’bad_income_upper:  651.9967484053386\n"
     ]
    }
   ],
   "source": [
    "# Your code is here\n",
    "def get_bootstrap_samples(data, n_samples):\n",
    "    \"\"\"Generate bootstrap samples using the bootstrap method.\"\"\"\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "def stat_intervals(stat, alpha):\n",
    "    \"\"\"Produce an interval estimate.\"\"\"\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries\n",
    "\n",
    "# Save the data about the good and bad customers to split the dataset\n",
    "good_customers_income = table[table['SeriousDlqin2yrs'] == False]['MonthlyIncome'].values\n",
    "bad_customers_income= table[table['SeriousDlqin2yrs'] == True]['MonthlyIncome'].values\n",
    "# Set the seed for reproducibility of the results\n",
    "np.random.seed(17)\n",
    "# Generate the samples using bootstrapping and calculate the mean for each of them\n",
    "good_income_mean_scores = [np.mean(sample) \n",
    "                       for sample in get_bootstrap_samples(good_customers_income, 1000)]\n",
    "bad_income_mean_scores = [np.mean(sample) \n",
    "                       for sample in get_bootstrap_samples(bad_customers_income, 1000)]\n",
    "# Print the resulting interval estimates\n",
    "good_mean_interval = stat_intervals(good_income_mean_scores, 0.1)\n",
    "bad_mean_interval = stat_intervals(bad_income_mean_scores, 0.1)\n",
    "print(\"Monthly income of good customers: mean interval\", good_mean_interval)\n",
    "print(\"Monthly income of bad customers: mean interval\", bad_mean_interval)\n",
    "print(\"Difference good_income_lowerâˆ’bad_income_upper: \", good_mean_interval[0] - bad_mean_interval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45063, 7), (45063,))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31544, 7), (13519, 7), (31544,), (13519,))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_share = 0.7\n",
    "train_size = int(train_share * X.shape[0])\n",
    "\n",
    "X_train, X_valid = X.iloc[:train_size, :], X.iloc[train_size:, :]\n",
    "y_train, y_valid = y.iloc[:train_size], y.iloc[train_size:]\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree, hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main performance metrics of a model is the area under the ROC curve. The ROC-AUC values lay between 0 and 1. The closer the value of ROC-AUC to 1, the better the classification is done.\n",
    "\n",
    "Find the values of `DecisionTreeClassifier` hyperparameters using the` GridSearchCV`, which maximize the area under the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `DecisionTreeClassifier` class to create a decision tree. Due to the imbalance of the classes in the target, we add the balancing parameter. We also use the parameter `random_state = 17` for the reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=17, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=17,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with the trained model on the test data.\n",
    "tree_predictions = dt.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(y_valid, tree_predictions), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7547155854722982"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, tree_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look through such values of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_values = [5, 6, 7, 8, 9]\n",
    "max_features_values = [4, 5, 6, 7]\n",
    "tree_params = {'max_depth': max_depth_values,\n",
    "               'max_features': max_features_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix cross-validation parameters: stratified, 5 partitions with shuffle, \n",
    "`random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average ROC AUC for cross-validation 0.6505874941327614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# Perfrom cross-validation.\n",
    "cv_scores = cross_val_score(dt, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "print(\"average ROC AUC for cross-validation\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Task 3.</font>**\n",
    "Run GridSearch with the ROC AUC metric using the hyperparameters from the `tree_params` dictionary. What is the maximum ROC AUC value (round up to 2 decimals)? We call cross-validation stable if the standard deviation of the metric on the cross-validation is less than 1%. Was cross-validation stable under optimal combinations of hyperparameters (i.e., providing a maximum of the mean ROC AUC value for cross-validation)?\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a5_q3__*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.82, no\n",
    "- 0.84, no\n",
    "- 0.82, yes\n",
    "- 0.84, yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=17,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [5, 6, 7, 8, 9], 'max_features': [4, 5, 6, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code is here\n",
    "tree_grid = GridSearchCV(estimator = dt, param_grid = tree_params, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
    "tree_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_max_depth:  7\n",
      "best_max_features:  4\n",
      "Best cross validaton score 0.82\n",
      "standard deviation of the metric on the cross-validation 0.00465\n"
     ]
    }
   ],
   "source": [
    "best_max_depth = tree_grid.best_params_['max_depth']\n",
    "best_max_features = tree_grid.best_params_['max_features']\n",
    "\n",
    "print(\"best_max_depth: \", best_max_depth)\n",
    "print(\"best_max_features: \", best_max_features)\n",
    "\n",
    "print(\"Best cross validaton score\", round(tree_grid.best_score_, 2))\n",
    "print(\"standard deviation of the metric on the cross-validation\", \\\n",
    "      round(tree_grid.cv_results_['std_test_score'][tree_grid.best_index_], 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_tree = DecisionTreeClassifier(random_state=17, class_weight='balanced', max_depth = best_max_depth, max_features = best_max_features)\n",
    "tuned_tree.fit(X_train, y_train)\n",
    "tuned_tree_predictions = tuned_tree.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tuned_tree_predictions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(y_valid, tuned_tree_predictions), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RandomForest implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Task 4.</font>**\n",
    "Implement your own random forest using `DecisionTreeClassifier` with the best parameters from the previous task. There will be 10 trees, the predicted probabilities of which you need to average.\n",
    "\n",
    "Brief specification:\n",
    " - Use the base code below\n",
    " - In the `fit` method in the loop (`i` from 0 to `n_estimators-1`), fix the seed equal to (`random_state + i`).The idea is that at each iteration the seed is new, and all the values could be reproduced.\n",
    " - After fixing the seed, select `max_features` features **without substituting**, save the list of selected id tags in `self.feat_ids_by_tree`\n",
    " - Also make a bootstrap-sample (i.e. **with replacement**) from the set of objects IDs\n",
    " - Train the tree with the same `max_depth`, `max_features` and `random_state`, as for `RandomForestClassifierCustom` on the sample with the necessary subset of objects and features\n",
    " - The `fit` method returns the current instance of the class `RandomForestClassifierCustom`, that is `self`\n",
    " - In the `predict_proba` method, we need to loop through all the trees. The test sample needs to take those features on which the corresponding tree was trained, and make a probability forecast (`predict_proba` now for the tree). The method should return average value of forecasts for all trees.\n",
    "\n",
    "Perform cross-validation. What is the average ROC AUC for cross-validation? Select the closest value.\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a5_q4__*\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.823\n",
    "- 0.833\n",
    "- 0.843\n",
    "- 0.853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class RandomForestClassifierCustom(BaseEstimator):\n",
    "    def __init__(self, n_estimators=10, max_depth=10, max_features=10, \n",
    "                 random_state=17):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.trees = []\n",
    "        self.feat_ids_by_tree = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Your code is here\n",
    "        for i in range(self.n_estimators):            \n",
    "            np.random.seed(self.random_state + i)        \n",
    "            random_features = np.random.choice(a = X.columns.values, size = self.max_features, replace = False)\n",
    "            self.feat_ids_by_tree.append(random_features)\n",
    "            bootstrap_indices = np.random.randint(0, len(X), size = len(X))\n",
    "            X_train = X.iloc[bootstrap_indices][random_features]\n",
    "            y_train = y.iloc[bootstrap_indices]\n",
    "\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth,\\\n",
    "                                          max_features=self.max_features,\\\n",
    "                                          random_state=self.random_state)\n",
    "            tree.fit(X_train, y_train)            \n",
    "            self.trees.append(tree)\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probas = []\n",
    "        for i in range(self.n_estimators):\n",
    "            feat = self.feat_ids_by_tree[i]\n",
    "            tree = self.trees[i]\n",
    "            proba = tree.predict_proba(X[feat])\n",
    "            probas.append(proba)\n",
    "        return np.mean(a = probas, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifierCustom(max_depth=7, max_features=4, n_estimators=10,\n",
       "               random_state=17)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_forest = RandomForestClassifierCustom(max_depth = best_max_depth, max_features = best_max_features)\n",
    "custom_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average ROC AUC for cross-validation 0.8285133285249264\n"
     ]
    }
   ],
   "source": [
    "# Perfrom cross-validation.\n",
    "cv_scores = cross_val_score(custom_forest, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "print(\"average ROC AUC for cross-validation\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_forest_pred_probs = custom_forest.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(custom_forest_pred_probs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.833"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(y_valid, custom_forest_pred_probs), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Task 5.</font>**\n",
    "Let us compare our own implementation of a random forest with `sklearn` version of it. To do this, use `RandomForestClassifier (class_weight='balanced', random_state = 17)`, specify all the same values for `max_depth` and` max_features` as before. What average value of ROC AUC on cross-validation we finally got? Select the closest value.\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a5_q5__*\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.823\n",
    "- 0.833\n",
    "- 0.843\n",
    "- 0.853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=7, max_features=4,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=17,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 10, max_depth = best_max_depth, max_features = best_max_features, \\\n",
    "                                class_weight='balanced', \\\n",
    "                                random_state = 17)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average ROC AUC for cross-validation 0.8282292143916085\n"
     ]
    }
   ],
   "source": [
    "# Perfrom cross-validation.\n",
    "cv_scores = cross_val_score(forest, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "print(\"average ROC AUC for cross-validation\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the test data.\n",
    "forest_pred_probs = forest.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEAlJREFUeJzt3X+snmV9x/H3Ryq6zR8gPRDWlh0WayKa+CMNsvjHVAwUWCh/wIKZs5rGJo4tLrofsP3BBpLglsliom7NaKxGhermaJSNNQhxWwQpA1FgpEdkcFJiKy1shsiGfvfHc1UP9bTPc9rT5znt9X4lJ899f+/rfp7rvnLO+Zz750lVIUnqz4sm3QFJ0mQYAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROLZt0Bw5l+fLlNT09PeluSNIx5d577/1BVU0Na7ekA2B6epodO3ZMuhuSdExJ8l+jtPMQkCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdWpJ3wl8pKav/OpEPvex6y+ayOdK0kK4ByBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOjVSACR5LMm3k9yfZEervSrJ9iQ72+vJrZ4kH08yk+SBJG+e8z7rW/udSdYfnU2SJI1iIXsAb6+qN1bVmjZ/JXB7Va0Gbm/zABcAq9vXRuBTMAgM4GrgLcDZwNX7Q0OSNH5HcghoHbClTW8BLplT/0wN3AWclOR04Hxge1Xtrap9wHZg7RF8viTpCIwaAAX8S5J7k2xstdOq6kmA9npqq68Anpiz7myrHawuSZqAUf8l5FuraleSU4HtSf7zEG0zT60OUX/hyoOA2QhwxhlnjNg9SdJCjbQHUFW72utu4MsMjuF/vx3aob3ubs1ngVVzVl8J7DpE/cDP2lRVa6pqzdTU1MK2RpI0sqEBkOSXkrx8/zRwHvAdYBuw/0qe9cAtbXob8J52NdA5wDPtENFtwHlJTm4nf89rNUnSBIxyCOg04MtJ9rf/fFX9c5J7gK1JNgCPA5e19rcCFwIzwLPA+wCqam+Sa4F7Wrtrqmrvom2JJGlBhgZAVT0KvGGe+lPAufPUC7jiIO+1Gdi88G5KkhabdwJLUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHVq5ABIckKS+5J8pc2fmeTuJDuT3JzkxFZ/SZufacun57zHVa3+SJLzF3tjJEmjW8gewAeBh+fMfxS4oapWA/uADa2+AdhXVa8GbmjtSHIWcDnwOmAt8MkkJxxZ9yVJh2ukAEiyErgI+Ls2H+AdwJdaky3AJW16XZunLT+3tV8H3FRVz1XV94AZ4OzF2AhJ0sKNugfw18AfAT9p86cAT1fV821+FljRplcATwC05c+09j+tz7POTyXZmGRHkh179uxZwKZIkhZiaAAk+Q1gd1XdO7c8T9MasuxQ6/ysULWpqtZU1Zqpqalh3ZMkHaZlI7R5K3BxkguBlwKvYLBHcFKSZe2v/JXArtZ+FlgFzCZZBrwS2Dunvt/cdSRJYzY0AKrqKuAqgCRvA/6gqn4ryReBS4GbgPXALW2VbW3+G23516qqkmwDPp/kY8AvA6uBby7u5iwN01d+dSKf+9j1F03kcyUdm0bZAziYPwZuSvIR4D7gxla/EfhskhkGf/lfDlBVDybZCjwEPA9cUVU/PoLPlyQdgQUFQFXdCdzZph9lnqt4qupHwGUHWf864LqFdlKStPi8E1iSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdGhoASV6a5JtJvpXkwSR/3upnJrk7yc4kNyc5sdVf0uZn2vLpOe91Vas/kuT8o7VRkqThRtkDeA54R1W9AXgjsDbJOcBHgRuqajWwD9jQ2m8A9lXVq4EbWjuSnAVcDrwOWAt8MskJi7kxkqTRDQ2AGvhhm31x+yrgHcCXWn0LcEmbXtfmacvPTZJWv6mqnquq7wEzwNmLshWSpAUb6RxAkhOS3A/sBrYD3wWerqrnW5NZYEWbXgE8AdCWPwOcMrc+zzqSpDEbKQCq6sdV9UZgJYO/2l87X7P2moMsO1j9BZJsTLIjyY49e/aM0j1J0mFY0FVAVfU0cCdwDnBSkmVt0UpgV5ueBVYBtOWvBPbOrc+zztzP2FRVa6pqzdTU1EK6J0lagFGuAppKclKb/gXgncDDwB3Apa3ZeuCWNr2tzdOWf62qqtUvb1cJnQmsBr65WBsiSVqYZcObcDqwpV2x8yJga1V9JclDwE1JPgLcB9zY2t8IfDbJDIO//C8HqKoHk2wFHgKeB66oqh8v7uZIkkY1NACq6gHgTfPUH2Weq3iq6kfAZQd5r+uA6xbeTUnSYvNOYEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTg0NgCSrktyR5OEkDyb5YKu/Ksn2JDvb68mtniQfTzKT5IEkb57zXutb+51J1h+9zZIkDTPKHsDzwIer6rXAOcAVSc4CrgRur6rVwO1tHuACYHX72gh8CgaBAVwNvAU4G7h6f2hIksZvaABU1ZNV9R9t+n+Ah4EVwDpgS2u2BbikTa8DPlMDdwEnJTkdOB/YXlV7q2ofsB1Yu6hbI0ka2YLOASSZBt4E3A2cVlVPwiAkgFNbsxXAE3NWm221g9UlSRMwcgAkeRnw98DvV9V/H6rpPLU6RP3Az9mYZEeSHXv27Bm1e5KkBRopAJK8mMEv/89V1T+08vfboR3a6+5WnwVWzVl9JbDrEPUXqKpNVbWmqtZMTU0tZFskSQswylVAAW4EHq6qj81ZtA3YfyXPeuCWOfX3tKuBzgGeaYeIbgPOS3JyO/l7XqtJkiZg2Qht3gr8NvDtJPe32p8A1wNbk2wAHgcua8tuBS4EZoBngfcBVNXeJNcC97R211TV3kXZCknSgg0NgKr6N+Y/fg9w7jztC7jiIO+1Gdi8kA5Kko4O7wSWpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqWWT7oAWz/SVX53YZz92/UUT+2xJh8c9AEnqlAEgSZ0aGgBJNifZneQ7c2qvSrI9yc72enKrJ8nHk8wkeSDJm+ess76135lk/dHZHEnSqEbZA/g0sPaA2pXA7VW1Gri9zQNcAKxuXxuBT8EgMICrgbcAZwNX7w8NSdJkDA2Aqvo6sPeA8jpgS5veAlwyp/6ZGrgLOCnJ6cD5wPaq2ltV+4Dt/HyoSJLG6HDPAZxWVU8CtNdTW30F8MScdrOtdrD6z0myMcmOJDv27NlzmN2TJA2z2CeBM0+tDlH/+WLVpqpaU1VrpqamFrVzkqSfOdwA+H47tEN73d3qs8CqOe1WArsOUZckTcjhBsA2YP+VPOuBW+bU39OuBjoHeKYdIroNOC/Jye3k73mtJkmakKF3Aif5AvA2YHmSWQZX81wPbE2yAXgcuKw1vxW4EJgBngXeB1BVe5NcC9zT2l1TVQeeWJYkjdHQAKiqdx1k0bnztC3gioO8z2Zg84J6J0k6arwTWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXK/wimY5r/BU06fAaAFsUkfxFLOjweApKkThkAktQpA0CSOmUASFKnDABJ6pQBIEmd8jJQ6TBN6tJX7z/QYnEPQJI6ZQBIUqc8BCQdY3z8hRaLewCS1Cn3ACSNzBPfxxf3ACSpUwaAJHXKQ0CSljwPPR0d7gFIUqcMAEnqlAEgSZ0yACSpU54ElqSDON7vuh77HkCStUkeSTKT5Mpxf74kaWCsAZDkBOATwAXAWcC7kpw1zj5IkgbGvQdwNjBTVY9W1f8CNwHrxtwHSRLjD4AVwBNz5mdbTZI0ZuM+CZx5avWCBslGYGOb/WGSp4AfHO2OHYOW47jMx3GZn+MyvyU7LvnoEa3+K6M0GncAzAKr5syvBHbNbVBVm4BN++eT7KiqNePp3rHDcZmf4zI/x2V+vY/LuA8B3QOsTnJmkhOBy4FtY+6DJIkx7wFU1fNJfhe4DTgB2FxVD46zD5KkgbHfCFZVtwK3LmCVTcObdMlxmZ/jMj/HZX5dj0uqangrSdJxx2cBSVKnlkwADHtERJKXJLm5Lb87yfT4ezl+I4zLh5I8lOSBJLcnGenyr2PdqI8USXJpkkrSxZUeo4xLkt9s3zMPJvn8uPs4CSP8HJ2R5I4k97WfpQsn0c+xq6qJfzE4Ifxd4FeBE4FvAWcd0OZ3gL9p05cDN0+630tkXN4O/GKb/oDj8oJ2Lwe+DtwFrJl0v5fCuACrgfuAk9v8qZPu9xIZl03AB9r0WcBjk+73OL6Wyh7AKI+IWAdsadNfAs5NMt+NZceToeNSVXdU1bNt9i4G91Yc70Z9pMi1wF8APxpn5yZolHF5P/CJqtoHUFW7x9zHSRhlXAp4RZt+JQfcn3S8WioBMMojIn7apqqeB54BThlL7yZnoY/O2AD801Ht0dIwdFySvAlYVVVfGWfHJmyU75fXAK9J8u9J7kqydmy9m5xRxuXPgHcnmWVwleLvjadrk7VU/h/A0EdEjNjmeDPyNid5N7AG+PWj2qOl4ZDjkuRFwA3Ae8fVoSVilO+XZQwOA72Nwd7ivyZ5fVU9fZT7NkmjjMu7gE9X1V8l+TXgs21cfnL0uzc5S2UPYOgjIua2SbKMwW7a3rH0bnJGGReSvBP4U+DiqnpuTH2bpGHj8nLg9cCdSR4DzgG2dXAieNSfo1uq6v+q6nvAIwwC4Xg2yrhsALYCVNU3gJcyeE7QcW2pBMAoj4jYBqxv05cCX6t2xuY4NnRc2qGOv2Xwy7+H47kwZFyq6pmqWl5V01U1zeDcyMVVtWMy3R2bUX6O/pHBhQMkWc7gkNCjY+3l+I0yLo8D5wIkeS2DANgz1l5OwJIIgHZMf/8jIh4GtlbVg0muSXJxa3YjcEqSGeBDwHH/38RGHJe/BF4GfDHJ/UmO+2crjTgu3RlxXG4DnkryEHAH8IdV9dRkejweI47Lh4H3J/kW8AXgvR38gemdwJLUqyWxByBJGj8DQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTv0/SvVqVGocNrwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(custom_forest_pred_probs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(y_valid, forest_pred_probs), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sklearn` RandomForest, hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Task 6.</font>** \n",
    "In the third task, we found the optimal hyperparameters for one tree. However it could be that these parameters are not optimal for an ensemble. Let's check this assumption with `GridSearchCV` `(RandomForestClassifier (class_weight='balanced', random_state = 17)` ). Now we extend the value of `max_depth` up to 15, because the trees need to be deeper in the forest (you should be aware of it from the [article](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-5-ensembles-of-algorithms-and-random-forest-8e05246cbba7)). What are the best values of hyperparameters now?\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a5_q6__*\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- `max_depth=8, max_features=4`\n",
    "- `max_depth=9, max_features=5`\n",
    "- `max_depth=10, max_features=6`\n",
    "- `max_depth=11, max_features=7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_values = range(5, 15)\n",
    "max_features_values = [4, 5, 6, 7]\n",
    "forest_params = {'max_depth': max_depth_values,\n",
    "                'max_features': max_features_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=17,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'max_depth': range(5, 15), 'max_features': [4, 5, 6, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code is here\n",
    "tree_grid = GridSearchCV(estimator = RandomForestClassifier (class_weight='balanced', random_state = 17), \\\n",
    "                         param_grid = forest_params, n_jobs = 8, cv=skf, scoring='roc_auc')\n",
    "tree_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 8, 'max_features': 4}\n",
      "Best cross validaton score 0.8309404314724571\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\", tree_grid.best_params_)\n",
    "print(\"Best cross validaton score\", tree_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression, hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Task 7.</font>**  Now let's compare our results with logistic regression (we indicate `class_weight = 'balanced'` and `random_state = 17`). Do a full search by the parameter `C` from a wide range of values `np.logspace (-8, 8, 17)`.\n",
    "Now we will build a pipeline - first apply scaling, then train the model.\n",
    "\n",
    "Learn about the pipelines and make cross-validation. What is the best average ROC AUC? Select the closest value.\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a5_q7__*\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.778\n",
    "- 0.788\n",
    "- 0.798\n",
    "- 0.808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "logit = LogisticRegression(random_state=17, class_weight='balanced')\n",
    "\n",
    "logit_pipe = Pipeline([('scaler', scaler), ('logit', logit)])\n",
    "logit_pipe_params = {'logit__C': np.logspace(-8, 8, 17)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logit', LogisticRegression(C=0.7435328430129343, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=17,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'logit__C': array([1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01,\n",
       "       1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07,\n",
       "       1.e+08])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid = GridSearchCV(logit_pipe, logit_pipe_params, n_jobs = 8, cv=skf, scoring='roc_auc')\n",
    "logit_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: 10000.0\n",
      "Best cross validaton score 0.7825520296650231\n"
     ]
    }
   ],
   "source": [
    "best_C = logit_grid.best_params_['logit__C']\n",
    "print(\"Best params:\", best_C)\n",
    "print(\"Best cross validaton score\", logit_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pipe = Pipeline([('scaler', scaler), \\\n",
    "                       ('logit', LogisticRegression(C = best_C, random_state=17, class_weight='balanced'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logit', LogisticRegression(C=10000.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=17,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pred_probs = logit_pipe.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(logit_pred_probs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.787"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(y_valid, logit_pred_probs), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression and RandomForest on sparse features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of a small number of features, random forest was proved to be better than logistic regression. However, one of the main disadvantages of trees is how they work with sparse data, for example, with texts. Let's compare logistic regression and random forest in a new task.\n",
    "Download dataset with reviews of movies [here](http://d.pr/f/W0HpZh). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    32492\n",
       "0    17508\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download data\n",
    "df = pd.read_csv(\"../../data/movie_reviews_train.csv\", nrows=50000)\n",
    "\n",
    "# Split data to train and test\n",
    "X_text = df[\"text\"]\n",
    "y_text = df[\"label\"]\n",
    "\n",
    "# Classes counts\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000,), (15000,), (35000,), (15000,))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_share = 0.7\n",
    "train_size = int(train_share * X_text.shape[0])\n",
    "\n",
    "X_text_train, X_text_valid = X_text.iloc[:train_size], X_text.iloc[train_size:]\n",
    "y_text_train, y_text_valid = y_text.iloc[:train_size], y_text.iloc[train_size:]\n",
    "X_text_train.shape, X_text_valid.shape, y_text_train.shape, y_text_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split on 3 folds\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17)\n",
    "\n",
    "# In Pipeline we will modify the text and train logistic regression\n",
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n",
    "    ('clf', LogisticRegression(random_state=17))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Task 8.</font>** For Logistic Regression: iterate parameter `C` with values from the list [0.1, 1, 10, 100] and find the best ROC AUC in cross-validation. Select the closest answer.\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a5_q8__*\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.74\n",
    "- 0.75\n",
    "- 0.84\n",
    "- 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=17, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=100000, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "     ...alty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'clf__C': [0.1, 1, 10, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_grid = GridSearchCV(classifier, {'clf__C': [0.1, 1, 10, 100]}, n_jobs = 8, cv=skf, scoring='roc_auc')\n",
    "classifier_grid.fit(X_text_train, y_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: 1\n",
      "Best cross validaton score 0.8505167052205929\n"
     ]
    }
   ],
   "source": [
    "best_C = classifier_grid.best_params_['clf__C']\n",
    "print(\"Best params:\", best_C)\n",
    "print(\"Best cross validaton score\", classifier_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=100000, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "     ...alty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n",
    "    ('clf', LogisticRegression(C = best_C, random_state=17))])\n",
    "classifier.fit(X_text_train, y_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pred_probs = classifier.predict_proba(X_text_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(y_text_valid, classifier_pred_probs), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Task 9.</font>** Now try to perform the same operation with random forest. Similarly, look over all the values and get the maximum ROC AUC. Select the closest value.\n",
    "\n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a5_q9__*\n",
    "\n",
    "**<font color='red'>Answer options:</font>**\n",
    "- 0.74\n",
    "- 0.75\n",
    "- 0.84\n",
    "- 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n",
    "    ('clf', RandomForestClassifier(random_state=17, n_jobs=-1))])\n",
    "\n",
    "min_samples_leaf = [1, 2, 3]\n",
    "max_features = [0.3, 0.5, 0.7]\n",
    "max_depth = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=17, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=100000, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "     ...timators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=17, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'clf__max_depth': [None], 'clf__max_features': [0.3, 0.5, 0.7], 'clf__min_samples_leaf': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid_params = {'clf__max_depth': max_depth, \\\n",
    "                   'clf__max_features': max_features, \\\n",
    "                   'clf__min_samples_leaf': min_samples_leaf}\n",
    "classifier_grid = GridSearchCV(classifier, clf_grid_params, n_jobs = 8, cv=skf, scoring='roc_auc')\n",
    "classifier_grid.fit(X_text_train, y_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__max_depth': None, 'clf__max_features': 0.3, 'clf__min_samples_leaf': 3}\n",
      "Best cross validaton score 0.7371508915024232\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\", classifier_grid.best_params_)\n",
    "print(\"Best cross validaton score\", classifier_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=100000, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "     ...timators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=17, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n",
    "    ('clf', RandomForestClassifier(random_state=17, \\\n",
    "                                   n_jobs=-1, \\\n",
    "                                   max_depth = classifier_grid.best_params_['clf__max_depth'], \\\n",
    "                                   max_features = classifier_grid.best_params_['clf__max_features'], \\\n",
    "                                   min_samples_leaf = classifier_grid.best_params_['clf__min_samples_leaf'] \\\n",
    "                                  ))])\n",
    "\n",
    "classifier.fit(X_text_train, y_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pred_probs = classifier.predict_proba(X_text_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(y_text_valid, classifier_pred_probs), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
